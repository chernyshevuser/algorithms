--УСЛОВИЕ ЗАДАЧИ--
Имеется n документов, каждый из которых представляет собой текст из слов. По этим документам требуется построить
поисковый индекс. На вход системе будут подаваться запросы. Запрос – некоторый набор слов. По запросу надо вывести
5 самых релевантных документов. Релевантность документа оценивается следующим образом: для каждого уникального слова
из запроса берётся число его вхождений в документ, полученные числа для всех слов из запроса суммируются. Итоговая
сумма и является релевантностью документа. Чем больше сумма, тем больше документ подходит под запрос.
Сортировка документов на выдаче производится по убыванию релевантности. Если релевантности документов совпадают, то
по возрастанию их порядковых номеров в базе (то есть во входных данных).

--ПРИНЦИП РАБОТЫ--
 Алгоритм действий:
 1) Входные строки разбиваются на отдельные слова. Затем обрабатываются, и информация записывается в map вида:
    {слово -> [ <количество в каждом тексте, номер текста> ]}, то есть каждому слову сопоставляется вектор из пар
 2) Считываются запросы и разбиваются на отдельные слова
 3) Поиск релевантности происходит следующим образом: каждое слово ищется в хеш-таблице, количество его вхождений
    добавляется к релевантности рассматриваемого текста. Затем данные по релевантности текстов сортируются и
    первые 5 выдаются в качестве ответа

--ВРЕМЕННАЯ СЛОЖНОСТЬ--
 Пусть n - кол-во текстов, длина которых O(1)

 Ввод текстов:
 computeWordFreqText O(1)
 computeWordFreqAll O(n*log(n)) (не уверен, что добавление n элементов в изначально пустой map работает именно
 столько, но так можно оценить нижнюю границу, потому что map устроен в виде дерева, которое можно обойти в порядке
 возрастания значений листьев. Но если бы это можно было сделать быстре, чем за O(n*log(n)), это бы значило, что
 можно реализовать сортировку объетов, основанную на сравнении, быстрее, чем за O(n*log(n)), что невозможно. Худший
 сценарий описать не могу, потому что на данный момент не разбираюсь в балансировках)

 Обработка одного запроса:
 computeRelevanceMap O(n*log(n)) - поиск слова работает за O(log(n)), операцию поиска нужно провести в худшем случае
 для всех n текстов
 computeRelevanceVec O(n + n*log(n)) = O(n*log(n)) - необходимо пройтись по релевантности всех n текстов
 и отсортировать их. Этап сортировки можно ускорить с O(k*log(k)) до O(k), где k - количество текстов, участвующих
 в составлении топа, но для тестов это не потребовалось, к тому же выигрыш в скорости был бы незначителен.
 getTopRelevanceVec O(1) - выбор первых пяти значений вектора

 Таким образом, обработка m запросов займет O(m*n*log(n))

 Общая сложность программы составляет O(n*log(n) + m*n*log(n)) = O(n*log(n)*(1 + m)) = O(n*m*log(n))

--ПРОСТРАНСТВЕННАЯ СЛОЖНОСТЬ--
 O(n^2), потому что каждому слову(число которых пропорционально n) сопоставляется информация о вхождении в каждый из
 n текстов
